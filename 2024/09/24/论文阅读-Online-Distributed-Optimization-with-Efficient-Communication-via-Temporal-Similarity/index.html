<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>论文阅读_Online_Distributed_Optimization_with_Efficient_Communication_via_Temporal_Similarity | 太想进步了</title><meta name="author" content="myc"><meta name="copyright" content="myc"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="论文阅读 Online Distributed Optimization with Efficient Communication via Temporal Similarity题目：基于时间相似性的高效通信在线分布式优化 出处：CCFA-INFOCOM 时间：2023 作者：Juncheng Wang∗, Ben Liang∗, Min Dong†, Gary Boudreau‡, and Al">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读_Online_Distributed_Optimization_with_Efficient_Communication_via_Temporal_Similarity">
<meta property="og:url" content="http://example.com/2024/09/24/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Online-Distributed-Optimization-with-Efficient-Communication-via-Temporal-Similarity/index.html">
<meta property="og:site_name" content="太想进步了">
<meta property="og:description" content="论文阅读 Online Distributed Optimization with Efficient Communication via Temporal Similarity题目：基于时间相似性的高效通信在线分布式优化 出处：CCFA-INFOCOM 时间：2023 作者：Juncheng Wang∗, Ben Liang∗, Min Dong†, Gary Boudreau‡, and Al">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/1.jpg">
<meta property="article:published_time" content="2024-09-24T01:44:35.000Z">
<meta property="article:modified_time" content="2024-10-14T15:30:05.409Z">
<meta property="article:author" content="myc">
<meta property="article:tag" content="论文阅读">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/1.jpg"><link rel="shortcut icon" href="/img/1.png"><link rel="canonical" href="http://example.com/2024/09/24/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Online-Distributed-Optimization-with-Efficient-Communication-via-Temporal-Similarity/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '论文阅读_Online_Distributed_Optimization_with_Efficient_Communication_via_Temporal_Similarity',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2024-10-14 23:30:05'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/1.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="太想进步了"></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">论文阅读_Online_Distributed_Optimization_with_Efficient_Communication_via_Temporal_Similarity</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-09-24T01:44:35.000Z" title="发表于 2024-09-24 09:44:35">2024-09-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-10-14T15:30:05.409Z" title="更新于 2024-10-14 23:30:05">2024-10-14</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="论文阅读_Online_Distributed_Optimization_with_Efficient_Communication_via_Temporal_Similarity"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>论文阅读</p>
<h2 id="Online-Distributed-Optimization-with-Efficient-Communication-via-Temporal-Similarity"><a href="#Online-Distributed-Optimization-with-Efficient-Communication-via-Temporal-Similarity" class="headerlink" title="Online Distributed Optimization with Efficient Communication via Temporal Similarity"></a>Online Distributed Optimization with Efficient Communication via Temporal Similarity</h2><p>题目：基于时间相似性的高效通信在线分布式优化</p>
<p>出处：CCFA-INFOCOM</p>
<p>时间：2023</p>
<p>作者：Juncheng Wang∗, Ben Liang∗, Min Dong†, Gary Boudreau‡, and Ali Afana‡<br>∗Department of Electrical and Computer Engineering, University of Toronto, Canada,<br>†Department of Electrical, Computer and Software Engineering, Ontario Tech University, Canada, ‡Ericsson Canada, Canada</p>
<h3 id="摘要："><a href="#摘要：" class="headerlink" title="摘要："></a>摘要：</h3><p>考虑网络系统中的<strong>在线分布式优化</strong>，其中由服务器辅助的多个设备协同最小化可能<strong>随时间变化的全局损失函数序列的积累</strong>。为了减少通信量，设备向服务器发送<strong>量化和压缩</strong>的本地决策，从而产生嘈杂的全局决策。因此，在优化性能和通信开销之间存在权衡。现有的工作分别优化了计算和通信。相比之下，我们通过鼓励决策序列中的<strong>时间相似性来控制通信开销</strong>，共同<strong>考虑计算和通信随时间的变化</strong>。我们提出了一种有效的算法，<strong>称为具有时间相似性的在线分布式优化(ODOTS)</strong>，其中局部决策是计算和通信感知的。此外，ODOTS使用了一种新颖的可调虚拟队列，通过<strong>改进的Lyapunov漂移分析</strong>完全消除了通常假设的Slater条件。ODOTS在<strong>优化目标</strong>和<strong>约束违反</strong>上都提供了可证明的性能界限。作为一个示例应用程序，我们应用ODOTS来实现高效通信的联邦学习。我们基于真实图像分类的实验结果表明，与目前最佳的凸损失函数和非凸损失函数相比，<strong>ODOTS具有更高的分类精度和更低的通信开销</strong>。</p>
<h3 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h3><p>考虑网络系统在长期决策不相似约束下的在线分布式优化，以控制通信开销。我们提出了一种有效的ODOTS算法，通过一种新颖的<strong>可调虚拟队列</strong>来平衡优化的改进和<strong>随着时间的推移的通信成本</strong>。通过<strong>改进的Lyapunov漂移分析</strong>，我们证明了ODOTS同时从集中式每槽优化器和亚线性约束违反中实现了亚线性性能差距。当将ODOTS应用于联邦学习时，我们的实验结果表明，在提高测试准确性和减少通信开销方面，ODOTS比最先进的方法具有显著的性能优势。ODOTS尤其在通信预算紧张的系统中具有优势。</p>
<h3 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h3><p>分布式优化已经成为现代机器学习应用的基本工具，这需要大量的存储、计算和数据。它避免了任何单个服务器的负担过重，并且通过<strong>协调多个本地设备</strong>来处理机器学习任务，对故障具有鲁棒性。它还可以通过将数据保存在本地来减轻隐私问题。然而，将优化从中央服务器迁移到本地设备可能会导致它们之间的通信开销激增。这需要通信高效的分布式优化。大多数现有的关于通信高效分布式学习的工作都将计算和通信分开考虑，也就是说，<strong>诸如量化和压缩之类的通信设计是在机器学习模型参数已经确定之后进行的</strong>，例如通过标准梯度下降。然而，由于通信效率强烈依赖于所传输的信息，因此可以通过主动设计学习精度和通信的模型参数来进一步提高学习性能效率。换句话说，联合考虑计算和通信将更充分地考虑到它们之间的相互影响。</p>
<h4 id="研究目的"><a href="#研究目的" class="headerlink" title="研究目的"></a>研究目的</h4><p>针对大多数现有的工作都集中在离线优化上，不允许时变损失函数或考虑任何长期约束的问题，进行在线优化，我们计算一系列优化决策，以适应不可预测的系统动态。如何设计一个在线分布式优化算法，同时考虑计算和通信随时间的变化?</p>
<p>为了回答上述关键问题，我们必须解决几个挑战:</p>
<p>1)由于通信开销依赖于从设备传输到服务器的本地决策，因此在更新本地决策时，我们必须同时考虑它们的优化性能和通信成本。</p>
<p>2)有损量化大大降低了通信开销，但同时在优化决策中产生了错误，这些错误随着时间的推移在迭代计算过程中传播。</p>
<p>3)由于计算和通信之间的紧密耦合，我们必须适当平衡它们共同对优化性能和收敛速度的影响。</p>
<p>4)计算和通信都需要适当地制定和设计，以考虑环境随时间的不可预测的波动。</p>
<h4 id="论文贡献"><a href="#论文贡献" class="headerlink" title="论文贡献"></a>论文贡献</h4><p>1 在线分布式优化问题，服务器通过汇总<strong>来自设备的量化和压缩</strong>的局部决策来计算一系列全局优化决策以最小化累积的全局损失。为了减少通信开销，通过强制执行平均长期决策不相似约束来鼓励设备上计算的本地决策序列的时间相似性。</p>
<p>2 ODOTS产生的局部决策能够适应损失函数的不可预测波动，同时考虑到决策不相似约束的违反，从而限制了通信开销。ODOTS通过一种新颖的可调虚拟队列实现了这一点，该队列需要<strong>改进的Lyapunov漂移分析技术</strong>。值得注意的是，这<strong>消除了对Slater条件</strong>的要求，该条件通常在现有的基于虚拟队列的在线优化算法中被假设。</p>
<p>3 分析了计算和通信之间的紧密耦合，以及它们对ODOTS优化性能和收敛速度的共同影响。对于设备上所有时变权值序列，ODOTS与集中式每时隙最优决策序列的性能差距为0 (max{T（1 +μ ）/ 2, T（3 +ν ）/4})，违反T时隙长期决策不相似约束的性能差距为0 (max{T3 +μ/ 4, T7 +ν/ 8})，其中μ表示集中式每时隙优化器的增长率和量化误差，ν表示时变权值的累积变化。</p>
<p>4 应用ODOTS来实现高效通信的联邦学习。实验结果表明，在不同的场景下，与现有的最佳方案相比，<strong>对于凸和非凸损失函数</strong>，ODOTS<strong>都能以更低的通信开销</strong>获得<strong>更高的测试精度</strong>。</p>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><p>分布式优化中的通信效率</p>
<p>通信效率与分布式学习</p>
<p>在线凸优化与Lyapunov优化</p>
<h3 id="论文方法"><a href="#论文方法" class="headerlink" title="论文方法"></a>论文方法</h3><h4 id="问题引入"><a href="#问题引入" class="headerlink" title="问题引入"></a>问题引入</h4><p>考虑一个由N个本地设备和一台服务器组成的网络系统。系统以时隙方式工作，时间以t为索引。感兴趣的是一个具有全局损失函数$f_t(\mathbf{x})$在每时刻t的在线分布优化问题。它被定义为局部损失函数$f_t^n(\mathbf{x})$的加权平均值。w是权值，x是d维输入数据样本。</p>
<script type="math/tex; mode=display">
f_t(\mathbf{x})\triangleq\sum_{n=1}^Nw_t^nf_t^n(\mathbf{x})</script><p>有：</p>
<script type="math/tex; mode=display">
f_t^n(\mathbf{x})=\frac{1} {|\mathcal{D}_t^n|}\sum_{i=1}^{|\mathcal{D}_t^n|}l(\mathbf{x};\mathbf{u}_t^{n,i},v_t^{n,i})</script><p>在线分布式优化的目标是在服务器上计算一系列全局决策{xt}，使有限时间范围T内的累积全局损失最小化，即:</p>
<script type="math/tex; mode=display">
\min_{\{\mathbf{x}_t\}}\quad\sum_{t=1}^Tf_t(\mathbf{x}_t).</script><h4 id="量化压缩"><a href="#量化压缩" class="headerlink" title="量化压缩"></a>量化压缩</h4><p>对于累积全局损失的分布式最小化，每个设备n生成其局部决策序列${x_t^n}$。服务器将本地决策${x_t^n}$从N个设备传输到服务器可能会导致大量通信开销。这可能是具有挑战性和耗时的。</p>
<p>未来高效通信，传输到服务器前对本地决策进行量化，生成量化决策：</p>
<script type="math/tex; mode=display">
\hat{x}_t^{n,i}=x_{\max}\cdot\mathrm{sign}(x_t^{n,i})\cdot\mathrm{map}(x_t^{n,i};x_{\max},s)</script><p>传递量化的局部决策需要有效的编码将$\hat{x}^{n}$转换为位流。（条件熵编码可以大大降低通信开销）。由于有损量化，服务器只能计算一个有噪声的全局决策$\hat{x}_{t+1}$，其中n代表全局量化误差（噪声）。</p>
<script type="math/tex; mode=display">
\mathbf{\hat{x}}_{t+1}=\sum_{n=1}^Nw_t^n\mathbf{\hat{x}}_t^n=\mathbf{x}_{t+1}+\mathbf{n}_{t+1}</script><p>${\hat{x}_{t+1}^n}$的有损传输可以很容易地与提出的算法及其性能分析相结合。</p>
<h4 id="问题表示"><a href="#问题表示" class="headerlink" title="问题表示"></a>问题表示</h4><p>核心目标：同时考虑全局损失最小化和局部决策通信开销。</p>
<p>直接建模时间相似性编码方案是具有挑战性的，因为它依赖于联合概率密度。论文通过重视信息源之间的差异来解决这个问题，并通过限制决策不相似的数量$|\mathbf{x}_t^n-\hat{\mathbf{x}}_{t-1}^n|^2$来控制通信开销(欧几里得范数）。</p>
<script type="math/tex; mode=display">
\begin{aligned}\mathbf{P1}:\quad\min_{\{\mathbf{x}_{t}^{n}\in\mathcal{X}\}}&\sum_{t=1}^{T}f_{t}(\hat{\mathbf{x}}_{t})\\
\mathrm{s.t.}&\frac{1}{N}\sum_{t=1}^{T}\sum_{n=1}^{N}g_{t}^{n}(\mathbf{x}_{t}^{n})\leq0\\
 \end{aligned}</script><script type="math/tex; mode=display">
g_t^n(\mathbf{x})\triangleq\|\mathbf{x}-\hat{\mathbf{x}}_{t-1}^n\|^2-\epsilon</script><p>计算一个局部决策序列${x_t^n}$，以最小化有噪声全局决策序列$\hat{x}_{t}$产生的累积损失，同时保证平均长期决策不相似约束得到满足。由于损失和约束函数的时变，P1是一个在线优化问题。</p>
<p>每个时间的最优解（全局信息）为：</p>
<script type="math/tex; mode=display">
\mathbf{x}_t^{\text{ctr}}\in\arg\min\{f_t(\mathbf{x})|g_t^n(\mathbf{x})\leq0,\forall n\}.</script><p>论文的目标是开发一种有约束的在线分布式优化算法，以计算具有亚线性性能差距到$\mathbf{x}_t^{\text{ctr}}$的P1的在线分布式解序列，即以及亚线性约束违反。性能差距和约束违反的次线性性是重要的;这意味着在线分布式解在时间平均性能方面接近于$\mathbf{x}_t^{\text{ctr}}$，并且长期约束是渐近满足的。</p>
<h4 id="Lyapunov优化与具体算法"><a href="#Lyapunov优化与具体算法" class="headerlink" title="Lyapunov优化与具体算法"></a>Lyapunov优化与具体算法</h4><p>在每个设备中引入虚拟队列（p1）：</p>
<script type="math/tex; mode=display">
Q_{t+1}^n=\begin{bmatrix}(1-\gamma^2)Q_t^n+\gamma\eta g_t^n(\mathbf{x}_t^n)\end{bmatrix}_+</script><p>其中γ∈(0,1)是虚拟队列上的调优因子，η &gt; 0是约束函数上的加权因子，[a]+ = max{a, 0}是投影算子Qn t的作用类似于P1的拉格朗日乘法器或违反约束的积压队列。这个新的可调虚拟队列提供了Qn t的一个简单上界，它不需要通常假定的基于虚拟队列在线的Slater条件优化算法。为了克服不能再直接将虚拟队列上界转移到约束违反界技术困难，论文将使用一种新的改进的Lyapunov漂移分析技术来约束违反项。</p>
<p>将p1转化为局部优化：</p>
<script type="math/tex; mode=display">
\mathbf{P2}^n: \min_{\mathbf{x}\in\mathcal{X}} \langle\nabla f_t^n(\hat{\mathbf{x}}_t),\mathbf{x}-\hat{\mathbf{x}}_t\rangle+\alpha\|\mathbf{x}-\hat{\mathbf{x}}_t\|^2+\eta Q_t^ng_t^n(\mathbf{x})</script><p>与最初的P1相比，长期决策不相似约束被转化为控制$g_t^n(\mathbf{x}_t^n)$以维持队列稳定性。求解凸优化问题P2n的直观方法是最小化修正漂移+惩罚+违反项的上界，以权衡损失最小化和随时间的约束违反。对p2n求梯度=0并且投影到x上，就得到了最优解。ODOTS的局部决策更新是计算和通信感知的，即随着时间的推移，自动平衡优化的改进和通信的成本。</p>
<p><strong><img src="/2024/09/24/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Online-Distributed-Optimization-with-Efficient-Communication-via-Temporal-Similarity/1.jpg" class="" title="This is an test image"></strong></p>
<p><strong><img src="/2024/09/24/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Online-Distributed-Optimization-with-Efficient-Communication-via-Temporal-Similarity/2.jpg" class="" title="This is an test image"></strong></p>
<h4 id="性能bound"><a href="#性能bound" class="headerlink" title="性能bound"></a>性能bound</h4><p>本节为证明ODOTS在优化目标和时间决策不相似约束中都提供了强有力的性能保证（证明略）。特别是，ODOTS的独特设计需要新的分析技术来考虑噪声决策更新和可调虚拟队列的影响。</p>
<p>论文给每个器件n定义了一个修正的李雅普诺夫漂移</p>
<script type="math/tex; mode=display">
\Theta_t^n=\frac{1}{2\gamma}(Q_{t+1}^n-U)^2-\frac{1}{2\gamma}(Q_t^n-U)^2.</script><p>ODOTS与$\mathbf{x}_t^{\text{ctr}}$的性能差距的上限为</p>
<script type="math/tex; mode=display">
\begin{aligned}\sum_{t=1}^{T}(f_{t}(\hat{\mathbf{x}}_{t})-f_{t}(\mathbf{x}_{t}^{\mathrm{ctr}}))&\leq\frac{D^{2}T}{4\alpha}+2\gamma\eta^{2}G^{2}T+\frac{\eta^{2}G^{2}\Omega_{T}}{2\gamma^{3}}\\&+\alpha\big(R^{2}+\Lambda_{2,T}+2R(\Lambda_{T}+\Pi_{T})\big)\end{aligned}</script><p>ODOTS产生的约束违反的上界为</p>
<script type="math/tex; mode=display">
\begin{aligned}&\frac{1}{N}\sum_{t=1}^{T}\sum_{n=1}^{N}g_{t}^{n}(\mathbf{x}_{t}^{n})\leq\left(\frac{2\gamma^{2}T+2}{\gamma\eta^{2}}\right)^{\frac{1}{2}}\left(\frac{D^{2}T}{4\alpha}+2\gamma\eta^{2}G^{2}T\right.\\&+D(R+\delta)T+\alpha\big(R^{2}(1+\Xi_{T})+\Lambda_{2,T}+2R(\Lambda_{T}+\Pi_{T})\big)\bigg)^{\frac{1}{2}}\end{aligned}</script><p>最终的结论：</p>
<p><strong><img src="/2024/09/24/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Online-Distributed-Optimization-with-Efficient-Communication-via-Temporal-Similarity/3.jpg" class="" title="This is an test image"></strong></p>
<p>此处论文没有证明。但将参数带入即可得到论文的结果。</p>
<p>特别是，如果μ &lt; 1且ν &lt; 1，即系统变化在T上是次线性的，则性能差距和约束违反在T上都是次线性的。在动态不可预测的在线优化中，系统的次线性变化是实现次线性性能界限的标准必要条件(但通常是不足条件)。</p>
<h3 id="实验与结果"><a href="#实验与结果" class="headerlink" title="实验与结果"></a>实验与结果</h3><p>论文在联邦学习中进行了实验。考虑一个具有N = 10个设备和一个服务器的FL系统。基于真实世界的图像分类数据集，用于凸和非凸损失函数，在流行的MNIST数据集上评估了。使用多项逻辑回归的交叉熵损失。</p>
<p>评估指标：</p>
<p>计算性能指标：</p>
<p>时间平均测试精度+ A(T)</p>
<p>时间平均训练损失+ f(T)</p>
<p>通信性能指标：</p>
<p>条件熵编码B(T) </p>
<p>时间平均决策不相似度g (T)</p>
<p>结果：</p>
<p><strong><img src="/2024/09/24/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Online-Distributed-Optimization-with-Efficient-Communication-via-Temporal-Similarity/4.jpg" class="" title="This is an test image"></strong></p>
<p><strong><img src="/2024/09/24/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Online-Distributed-Optimization-with-Efficient-Communication-via-Temporal-Similarity/5.jpg" class="" title="This is an test image"></strong></p>
<h3 id="个人想法"><a href="#个人想法" class="headerlink" title="个人想法"></a>个人想法</h3><p>这是一篇应用李雅普诺夫漂移优化的论文，让我对李雅普诺夫漂移优化有了一点新的认识。论文针对在线分布式优化，共同考虑计算和通信随时间的变化，对于每个时间槽t，构造一个虚拟队列，实现了一个高效的联邦学习。对于论文的证明过程，作者给出比较详细的论证过程，整体上比较清晰。在实验部分中，对其他模型的对比也比较明显。</p>
<h3 id="引用内容（自用）："><a href="#引用内容（自用）：" class="headerlink" title="引用内容（自用）："></a>引用内容（自用）：</h3><p>ieeexplore：</p>
<p>@INPROCEEDINGS{10229086,<br>  author={Wang, Juncheng and Liang, Ben and Dong, Min and Boudreau, Gary and Afana, Ali},<br>  booktitle={IEEE INFOCOM 2023 - IEEE Conference on Computer Communications},<br>  title={Online Distributed Optimization with Efficient Communication via Temporal Similarity},<br>  year={2023},<br>  volume={},<br>  number={},<br>  pages={1-10},<br>  keywords={Performance evaluation;Costs;Federated learning;Computational efficiency;Servers;Noise measurement;Optimization},<br>  doi={10.1109/INFOCOM53939.2023.10229086}}</p>
<p>google学术：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@inproceedings&#123;wang2023online,</span><br><span class="line">  title=&#123;Online distributed optimization with efficient communication via temporal similarity&#125;,</span><br><span class="line">  author=&#123;Wang, Juncheng and Liang, Ben and Dong, Min and Boudreau, Gary and Afana, Ali&#125;,</span><br><span class="line">  booktitle=&#123;IEEE INFOCOM 2023-IEEE Conference on Computer Communications&#125;,</span><br><span class="line">  pages=&#123;1--10&#125;,</span><br><span class="line">  year=&#123;2023&#125;,</span><br><span class="line">  organization=&#123;IEEE&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Wang J, Liang B, Dong M, et al. Online distributed optimization with efficient communication via temporal similarity[C]//IEEE INFOCOM 2023-IEEE Conference on Computer Communications. IEEE, 2023: 1-10.</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">myc</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/09/24/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Online-Distributed-Optimization-with-Efficient-Communication-via-Temporal-Similarity/">http://example.com/2024/09/24/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Online-Distributed-Optimization-with-Efficient-Communication-via-Temporal-Similarity/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">太想进步了</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></div><div class="post_share"><div class="social-share" data-image="/img/1.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/2024/10/14/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%A8%A1%E6%9D%BF/" title="论文阅读模板"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">论文阅读模板</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/12/02/Asteroid-Resource-Efficient-Hybrid-Pipeline-Parallelism-for-Collaborative-DNN-Training-on-Heterogeneous-Edge-Devices/" title="Asteroid_Resource_Efficient_Hybrid_Pipeline_Parallelism_for_Collaborative DNN_Training_on_Heterogeneous_Edge_Devices"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-02</div><div class="title">Asteroid_Resource_Efficient_Hybrid_Pipeline_Parallelism_for_Collaborative DNN_Training_on_Heterogeneous_Edge_Devices</div></div></a></div><div><a href="/2025/04/25/FedDAT%EF%BC%9A%E4%B8%80%E7%A7%8D%E5%A4%9A%E6%A8%A1%E6%80%81%E5%BC%82%E6%9E%84%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/" title="FedDAT：一种多模态异构联邦学习中的基础模型微调方法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-25</div><div class="title">FedDAT：一种多模态异构联邦学习中的基础模型微调方法</div></div></a></div><div><a href="/2025/04/23/FedFMSL%EF%BC%9A%E4%BD%BF%E7%94%A8%E7%A8%80%E7%96%8F%E6%BF%80%E6%B4%BBLoRA%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/" title="FedFMSL：使用稀疏激活LoRA的基础模型的联邦学习"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-23</div><div class="title">FedFMSL：使用稀疏激活LoRA的基础模型的联邦学习</div></div></a></div><div><a href="/2025/04/25/FLORA-%E5%85%B7%E6%9C%89%E5%BC%82%E6%9E%84%E4%BD%8E%E7%A7%A9%E9%80%82%E5%BA%94%E7%9A%84%E8%81%94%E9%82%A6%E5%BE%AE%E8%B0%83%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" title="FLORA:具有异构低秩适应的联邦微调大型语言模型"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-25</div><div class="title">FLORA:具有异构低秩适应的联邦微调大型语言模型</div></div></a></div><div><a href="/2024/12/02/FlexNN-Efficient-and-Adaptive-DNN-Inference-on-Memory-Constrained-Edge-Devices/" title="FlexNN_Efficient_and_Adaptive_DNN_Inference_on_Memory_Constrained_Edge_Devices"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-02</div><div class="title">FlexNN_Efficient_and_Adaptive_DNN_Inference_on_Memory_Constrained_Edge_Devices</div></div></a></div><div><a href="/2025/04/21/LORA%EF%BC%9A%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%8E%E9%98%B6%E8%87%AA%E9%80%82%E5%BA%94/" title="LORA：大型语言模型的低阶自适应"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-21</div><div class="title">LORA：大型语言模型的低阶自适应</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/1.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">myc</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">北京理工大学-计算机学院</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Online-Distributed-Optimization-with-Efficient-Communication-via-Temporal-Similarity"><span class="toc-number">1.</span> <span class="toc-text">Online Distributed Optimization with Efficient Communication via Temporal Similarity</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%91%98%E8%A6%81%EF%BC%9A"><span class="toc-number">1.1.</span> <span class="toc-text">摘要：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA%EF%BC%9A"><span class="toc-number">1.2.</span> <span class="toc-text">结论：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF"><span class="toc-number">1.3.</span> <span class="toc-text">研究背景</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A0%94%E7%A9%B6%E7%9B%AE%E7%9A%84"><span class="toc-number">1.3.1.</span> <span class="toc-text">研究目的</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E8%B4%A1%E7%8C%AE"><span class="toc-number">1.3.2.</span> <span class="toc-text">论文贡献</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.4.</span> <span class="toc-text">相关工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E6%96%B9%E6%B3%95"><span class="toc-number">1.5.</span> <span class="toc-text">论文方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E5%BC%95%E5%85%A5"><span class="toc-number">1.5.1.</span> <span class="toc-text">问题引入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8F%E5%8C%96%E5%8E%8B%E7%BC%A9"><span class="toc-number">1.5.2.</span> <span class="toc-text">量化压缩</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E8%A1%A8%E7%A4%BA"><span class="toc-number">1.5.3.</span> <span class="toc-text">问题表示</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Lyapunov%E4%BC%98%E5%8C%96%E4%B8%8E%E5%85%B7%E4%BD%93%E7%AE%97%E6%B3%95"><span class="toc-number">1.5.4.</span> <span class="toc-text">Lyapunov优化与具体算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%A7%E8%83%BDbound"><span class="toc-number">1.5.5.</span> <span class="toc-text">性能bound</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E4%B8%8E%E7%BB%93%E6%9E%9C"><span class="toc-number">1.6.</span> <span class="toc-text">实验与结果</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%AA%E4%BA%BA%E6%83%B3%E6%B3%95"><span class="toc-number">1.7.</span> <span class="toc-text">个人想法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%EF%BC%88%E8%87%AA%E7%94%A8%EF%BC%89%EF%BC%9A"><span class="toc-number">1.8.</span> <span class="toc-text">引用内容（自用）：</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/25/FedDAT%EF%BC%9A%E4%B8%80%E7%A7%8D%E5%A4%9A%E6%A8%A1%E6%80%81%E5%BC%82%E6%9E%84%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/" title="FedDAT：一种多模态异构联邦学习中的基础模型微调方法">FedDAT：一种多模态异构联邦学习中的基础模型微调方法</a><time datetime="2025-04-25T06:53:42.000Z" title="发表于 2025-04-25 14:53:42">2025-04-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/25/FLORA-%E5%85%B7%E6%9C%89%E5%BC%82%E6%9E%84%E4%BD%8E%E7%A7%A9%E9%80%82%E5%BA%94%E7%9A%84%E8%81%94%E9%82%A6%E5%BE%AE%E8%B0%83%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" title="FLORA:具有异构低秩适应的联邦微调大型语言模型">FLORA:具有异构低秩适应的联邦微调大型语言模型</a><time datetime="2025-04-25T04:53:25.000Z" title="发表于 2025-04-25 12:53:25">2025-04-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/24/%E9%9D%9E%E5%9D%87%E5%8C%80%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96%E8%81%94%E9%82%A6%E5%BE%AE%E8%B0%83%EF%BC%9A%E4%B8%80%E7%A7%8D%E4%B8%A4%E5%B1%82%E4%BD%8E%E7%A7%A9%E8%87%AA%E9%80%82%E5%BA%94%E6%96%B9%E6%B3%95/" title="非均匀数据的个性化联邦微调，一种两层低秩自适应方法">非均匀数据的个性化联邦微调，一种两层低秩自适应方法</a><time datetime="2025-04-24T09:37:46.000Z" title="发表于 2025-04-24 17:37:46">2025-04-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/23/FedFMSL%EF%BC%9A%E4%BD%BF%E7%94%A8%E7%A8%80%E7%96%8F%E6%BF%80%E6%B4%BBLoRA%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/" title="FedFMSL：使用稀疏激活LoRA的基础模型的联邦学习">FedFMSL：使用稀疏激活LoRA的基础模型的联邦学习</a><time datetime="2025-04-23T11:38:39.000Z" title="发表于 2025-04-23 19:38:39">2025-04-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/21/LORA%EF%BC%9A%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%8E%E9%98%B6%E8%87%AA%E9%80%82%E5%BA%94/" title="LORA：大型语言模型的低阶自适应">LORA：大型语言模型的低阶自适应</a><time datetime="2025-04-21T06:55:23.000Z" title="发表于 2025-04-21 14:55:23">2025-04-21</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By myc</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>